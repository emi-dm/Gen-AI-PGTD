{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 Generando dígitos con PyTorch: ¡Tu primera aventura en IA Generativa! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 ¡Bienvenido al mundo de PyTorch! \n",
    "\n",
    "PyTorch es una de las bibliotecas de deep learning más utilizadas en el mundo. 💪 Aunque algunas partes de esta sesión práctica pueden parecer un poco intimidantes si es tu primera vez con PyTorch, ¡no te preocupes! Todos hemos estado ahí. 😊\n",
    "\n",
    "Si eres principiante, te recomiendo encarecidamente que primero te familiarices con PyTorch a través de estos tutoriales:\n",
    "\n",
    "* 📚 [Deep Learning Con PyTorch: Un Tutorial de 60 Minutos](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* 🖼️ [Entrenando un Clasificador en CIFAR10](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
    "\n",
    "Una vez que domines estos conceptos básicos, estarás listo para crear tus propios autoencoders. \n",
    "\n",
    "💡 **Mi consejo para ti**: Si quieres profundizar en los aspectos técnicos de PyTorch después de este ejercicio, navega por los tutoriales oficiales. ¡Descubrirás que PyTorch es una herramienta realmente poderosa! ⚡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 ¡Empecemos explorando nuestros datos!\n",
    "\n",
    "¿Conoces el conjunto de datos MNIST? 📊 Es como el \"Hola Mundo\" del machine learning, ¡y hoy será tu mejor amigo!\n",
    "\n",
    "**El conjunto de datos MNIST (Modified National Institute of Standards and Technology)** es una colección de dígitos escritos a mano que vas a usar para entrenar tu sistema de procesamiento de imágenes. \n",
    "\n",
    "📋 **¿Qué contiene exactamente?**\n",
    "- ✅ **60,000 imágenes de entrenamiento** (para que tu modelo aprenda)\n",
    "- ✅ **10,000 imágenes de prueba** (para evaluar qué tan bien aprendió)\n",
    "- ✅ **Cada imagen es de 28x28 píxeles** en escala de grises\n",
    "- ✅ **Los valores van de 0 (negro) a 1 (blanco)**\n",
    "- ✅ **Cada imagen está etiquetada** con el dígito que representa (0-9)\n",
    "\n",
    "🎯 **¿Por qué es tan importante?** Es considerado el punto de partida perfecto para cualquiera que quiera adentrarse en el reconocimiento de patrones y las redes neuronales. ¡Es tu puerta de entrada al mundo de la IA!\n",
    "\n",
    "💫 **¡Vamos a visualizarlos y ver qué magia puedes crear!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from src_vae.visualization.utils import display_data_samples\n",
    "\n",
    "# MNIST consists of 28x28 images, so the size of the data is\n",
    "data_shape = 28, 28\n",
    "data_size = data_shape[0] * data_shape[1]\n",
    "\n",
    "# Download and prepare data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = MNIST(root=\"data\", download=True, train=True, transform=transform)\n",
    "mnist_test = MNIST(root=\"data\", download=True, train=False, transform=transform)\n",
    "\n",
    "# Check data by displaying random images\n",
    "samples_indices = np.random.randint(len(mnist_train), size=10)\n",
    "mnist_img_list = [mnist_train[sample_idx][0] for sample_idx in samples_indices]\n",
    "display_data_samples(data=mnist_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are `mnist_train` and `mnist_test`?  Let's look at it.\n",
    "print(mnist_train)\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📥 ¡Cargando nuestros datos como un pro!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the first training image and its class label\n",
    "sample_image = mnist_train[0][0]  # sample_image is a \"PyTorch tensor\"\n",
    "sample_label = mnist_train[0][1]\n",
    "\n",
    "# Convert the Tensor into a numpy array\n",
    "sample_image_np = sample_image.numpy()\n",
    "print(\"Image size = \", sample_image_np.shape)\n",
    "\n",
    "# Call \"squeeze\" to remove the first dimension\n",
    "sample_image_np = sample_image_np.squeeze(0)\n",
    "print(\"Image size = \", sample_image_np.shape)\n",
    "\n",
    "# Plot\n",
    "plt.imshow(sample_image_np)\n",
    "print(\"The image label is \", sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏗️ ¡Construyamos tu primer autoencoder profundo!\n",
    "\n",
    "¡Ahora viene la parte emocionante! 🎉 Vamos a construir un autoencoder simple pero poderoso usando solo:\n",
    "\n",
    "🧠 **Capas densas** (también conocidas como completamente conectadas) - En PyTorch las llamamos **Linear**  \n",
    "⚡ **Funciones de activación ReLU** - Para dar vida a nuestras neuronas\n",
    "\n",
    "📐 **Arquitectura que crearemos:**\n",
    "\n",
    "- 🔗 **Codificador y decodificador**: Ambos con **3 capas** cada uno\n",
    "- 🎯 **Espacio latente**: **32 dimensiones** (¡aquí es donde ocurre la magia!)\n",
    "- 🌟 **Función de activación final**: **Sigmoid** (perfecta porque nuestros píxeles van de 0 a 1)\n",
    "\n",
    "¿Estás listo para ver cómo tu autoencoder aprende a \"entender\" y recrear dígitos? ¡Vamos allá! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "# Let's define the encoder architecture we want,\n",
    "# with some options to configure the input and output size\n",
    "def make_encoder(data_size, latent_space_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(data_size, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, latent_space_size),\n",
    "    )\n",
    "\n",
    "\n",
    "# Same thing for the decoder\n",
    "def make_decoder(data_size, latent_space_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(latent_space_size, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, data_size),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "\n",
    "# Now let's build our networks, with an arbitrary dimensionality of the latent space\n",
    "# and an input and output size depending on the data.\n",
    "latent_space_size = 2\n",
    "encoder = make_encoder(data_size, latent_space_size)\n",
    "decoder = make_decoder(data_size, latent_space_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤔 ¡Momento de reflexión!\n",
    "* 🎨 **¿Qué vamos a generar?**\n",
    "* 📏 **¿Cuál es el tamaño del espacio latente del autoencoder?**\n",
    "\n",
    "💭 *Tómate un momento para pensar en estas preguntas antes de continuar...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def autoencoder_forward_pass(encoder, decoder, x):\n",
    "    \"\"\"AE forward pass.\n",
    "\n",
    "    Args:\n",
    "        encoder: neural net that predicts a latent vector\n",
    "        decoder: neural net that projects a point in the latent space back into the image space\n",
    "        x: batch of N MNIST images\n",
    "\n",
    "    Returns:\n",
    "        loss: crossentropy loss\n",
    "        x_hat: batch of N reconstructed images\n",
    "    \"\"\"\n",
    "    in_shape = x.shape  # Save the input shape\n",
    "    encoder_input = torch.flatten(x, start_dim=1)  # Flatten the 2D image to a 1D tensor (for the linear layer)\n",
    "    z = encoder(encoder_input)  # Forward pass on the encoder (to get the latent space vector)\n",
    "    x_hat = decoder(z)  # Forward pass on the decoder (to get the reconstructed input)\n",
    "    x_hat = x_hat.reshape(in_shape)  # Restore the output to the original shape\n",
    "    loss = F.binary_cross_entropy(x_hat, x)  # Compute the reconstruction loss\n",
    "    return loss, x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 ¡Entrenamiento del modelo en acción!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Define some training hyperparameters\n",
    "epochs = 25\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "def train(forward_pass_fn, encoder, decoder, optimizer, train_data, val_data, device=\"cuda\"):\n",
    "    # Create dataloaders from the data\n",
    "    # Those are PyTorch's abstraction to help iterate over the data\n",
    "    data_loader_kwargs = {\"batch_size\": batch_size, \"num_workers\": os.cpu_count() - 1, \"pin_memory\": True}\n",
    "    train_dataloader = DataLoader(train_data, shuffle=True, **data_loader_kwargs)\n",
    "    val_dataloader = DataLoader(val_data, **data_loader_kwargs)\n",
    "\n",
    "    # Ensure that the networks are on the requested device (typically a GPU)\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    fit_pbar = tqdm(range(epochs), desc=\"Training\", unit=\"epoch\")\n",
    "    pbar_metrics = {\"train_loss\": None, \"val_loss\": None}\n",
    "    for epoch in fit_pbar:\n",
    "        # Train once over all the training data\n",
    "        for x, _ in train_dataloader:\n",
    "            x = x.to(device)  # Move the data tensor to the device\n",
    "            optimizer.zero_grad()  # Make sure gradients are reset\n",
    "            train_loss, _ = forward_pass_fn(encoder, decoder, x)  # Forward pass\n",
    "            train_loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update parameters w.r.t. optimizer and gradients\n",
    "            pbar_metrics[\"train_loss\"] = train_loss.item()\n",
    "            fit_pbar.set_postfix(pbar_metrics)\n",
    "\n",
    "        # At the end of the epoch, check performance against the validation data\n",
    "        for x, _ in val_dataloader:\n",
    "            x = x.to(device)  # Move the data tensor to the device\n",
    "            val_loss, _ = forward_pass_fn(encoder, decoder, x)\n",
    "            pbar_metrics[\"val_loss\"] = val_loss.item()\n",
    "            fit_pbar.set_postfix(pbar_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*encoder.parameters(), *decoder.parameters()])\n",
    "train(autoencoder_forward_pass, encoder, decoder, optimizer, mnist_train, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎉 **¡Momento de la verdad!** Vamos a visualizar los resultados para el conjunto de test y ver qué tan bien tu modelo aprendió a reconstruir los dígitos 🔍✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from src_vae.visualization.utils import display_autoencoder_results\n",
    "\n",
    "display_autoencoder_results(mnist_test, lambda x: autoencoder_forward_pass(encoder, decoder, x.cuda())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🗺️ Explorando el espacio latente\n",
    "\n",
    "🎯 **¡Hora de un experimento súper interesante!** \n",
    "\n",
    "Antes de pasar al autoencoder variacional, voy a hacer algo genial contigo. Regresa al inicio de este notebook y cambia el tamaño del espacio latente de **32 a 2 dimensiones** y vuelve a entrenar tu autoencoder.\n",
    "\n",
    "🔄 **¿Por qué 2 dimensiones?** ¡Porque podrás visualizar el espacio latente en un gráfico 2D y ver exactamente cómo tu modelo \"entiende\" los dígitos!\n",
    "\n",
    "✨ **Una vez que hayas hecho el cambio y reentrenado**, ejecuta la siguiente celda para explorar visualmente tu espacio latente. ¡Prepárate para sorprenderte! 🤩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell only if the autoencoder has a latent space size of 2.\n",
    "\n",
    "from src_vae.visualization.latent_space import explore_latent_space\n",
    "\n",
    "latent_space_size = 2\n",
    "\n",
    "explore_latent_space(\n",
    "    mnist_test,\n",
    "    lambda x: encoder(torch.flatten(x, start_dim=1)),\n",
    "    lambda z: decoder(z).reshape(data_shape),\n",
    "    encodings_label=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤔 ¡Pregunta para reflexionar!\n",
    "\n",
    "💭 **¿Por qué crees que con un espacio latente de 2 dimensiones obtienes imágenes reconstruidas menos precisas (más borrosas)?**\n",
    "\n",
    "*Piensa en términos de la cantidad de información que puede almacenar un espacio de 2 dimensiones vs uno de 32 dimensiones...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🌟 ¡Convirtamos tu autoencoder en VARIACIONAL!\n",
    "\n",
    "🎉 **¡Llegó el momento estelar!** Los autoencoders variacionales (VAE) son la evolución natural de lo que acabas de crear. Son muy similares, pero con superpoderes adicionales. 💫\n",
    "\n",
    "🔍 **¿Cuáles son las 3 diferencias clave que te enseñaré?**\n",
    "\n",
    "1. 📊 **El codificador del VAE genera vectores de media y varianza** (en lugar de un solo vector)\n",
    "2. 🎲 **La entrada del decodificador es un vector muestreado aleatoriamente** de una distribución Normal determinada por esos vectores de media y varianza\n",
    "3. 📈 **La función de pérdida tiene 2 términos**: \n",
    "   - ✅ La pérdida de reconstrucción (como en tu AE normal) \n",
    "   - ✅ **+ la divergencia KL** (para la salida del codificador)\n",
    "\n",
    "🧠 **El truco de reparametrización**: Como el gradiente no puede retropropagarse a través de un método de muestreo aleatorio, los VAE siempre vienen con este elegante truco matemático. ¡Es lo que hace posible que todo funcione! ⚡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "# Esta vez, empezamos directamente con un espacio latente de 2 dimensiones para visualizarlo fácilmente después\n",
    "latent_space_size = 2\n",
    "\n",
    "# En la práctica, un pequeño truco para implementar fácilmente las dos salidas del \n",
    "# codificador es simplemente duplicar el tamaño de su salida. Luego, podemos dividir \n",
    "# la salida por la mitad durante el paso hacia adelante!\n",
    "vae_encoder = make_encoder(data_size, latent_space_size * 2)\n",
    "vae_decoder = make_decoder(data_size, latent_space_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 ¡Preguntas para que reflexiones!\n",
    "\n",
    "🤔 **En la celda anterior**, usamos la misma función para construir las redes del codificador y decodificador del VAE que para el AE. La única diferencia es que el tamaño de salida del codificador está multiplicado por 2. **¿Por qué crees que es así?**\n",
    "\n",
    "🔧 **En la siguiente celda**, incluyo el **truco de reparametrización** en el **paso hacia adelante**. **¿Recuerdas por qué esto tiene que hacerse?**\n",
    "\n",
    "📏 **¿Cuál es el tamaño del espacio latente del VAE?**\n",
    "\n",
    "💡 *Tómate un momento para pensar en estas preguntas. ¡Te ayudarán a entender mejor la magia detrás de los VAE!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚙️ ¡Implementando el famoso \"truco de reparametrización\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "def kl_div(mu, logvar):\n",
    "    kl_div_by_samples = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "    return torch.mean(kl_div_by_samples)\n",
    "\n",
    "\n",
    "def vae_forward_pass(encoder, decoder, x):\n",
    "    \"\"\"VAE forward pass.\n",
    "\n",
    "    Args:\n",
    "        encoder: neural net that predicts a mean and a logvar vector\n",
    "        decoder: neural net that projects a point in the latent space back into the image space\n",
    "        x: batch of N MNIST images\n",
    "\n",
    "    Returns:\n",
    "        loss: crossentropy + kl_divergence loss\n",
    "        x_hat: batch of N reconstructed images\n",
    "    \"\"\"\n",
    "    in_shape = x.shape  # Save the input shape\n",
    "    encoder_input = torch.flatten(x, start_dim=1)  # Flatten the 2D image to a 1D tensor (for the linear layer)\n",
    "    encoding_distr = encoder(encoder_input)  # Forward pass on the encoder (to get the latent space posterior)\n",
    "    # Nothing changed so far!\n",
    "\n",
    "    # Second part of our trick!\n",
    "    # We separate the (unique) latent space posterior into its two halves: mean and logvar\n",
    "    mu, logvar = encoding_distr[:, :latent_space_size], encoding_distr[:, latent_space_size:]\n",
    "\n",
    "    # Reparametrization trick\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    z = mu + eps * std\n",
    "\n",
    "    # Decoding mostly stays the same. The only difference is the added 4th line below\n",
    "    x_hat = decoder(z)  # Forward pass on the decoder (to get the reconstructed input)\n",
    "    x_hat = x_hat.reshape(in_shape)  # Restore the output to the original shape\n",
    "    loss = F.binary_cross_entropy(x_hat, x)  # Compute the reconstruction loss\n",
    "    loss += 5e-3 * kl_div(mu, logvar)  # Loss now also includes the KL divergence term\n",
    "    return loss, x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚀 **¡Vamos a entrenar tu VAE y ver la magia en acción!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*vae_encoder.parameters(), *vae_decoder.parameters()])\n",
    "train(vae_forward_pass, vae_encoder, vae_decoder, optimizer, mnist_train, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎊 **¡Echemos un vistazo a los resultados de tu VAE entrenado!** \n",
    "\n",
    "💡 Recuerda que tu VAE tiene un espacio latente de 2 dimensiones, ¡así que podremos visualizarlo en un gráfico de dispersión! ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "display_autoencoder_results(mnist_test, lambda x: vae_forward_pass(vae_encoder, vae_decoder, x.cuda())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 ¡Más visualizaciones espectaculares!\n",
    "\n",
    "🌟 **¡Ahora que tienes un espacio latente en dos dimensiones**, puedes visualizarlo fácilmente y observar cómo se distribuyen los datos de una manera súper cool!\n",
    "\n",
    "### 👀 ¿Ves la diferencia entre este espacio latente y el del autoencoder anterior?\n",
    "\n",
    "💭 *¡Presta especial atención a cómo se organizan los diferentes dígitos en el espacio 2D!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from src_vae.visualization.latent_space import explore_latent_space\n",
    "\n",
    "explore_latent_space(\n",
    "    mnist_test,\n",
    "    lambda x: vae_encoder(torch.flatten(x, start_dim=1))[:, :latent_space_size],\n",
    "    lambda z: vae_decoder(z).reshape(data_shape),\n",
    "    encodings_label=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎮 ¡Hora de jugar con tu generador de dígitos!\n",
    "\n",
    "🎯 **En la siguiente celda**, te doy el poder de decodificar cualquier vector `z` que selecciones del espacio latente. ¡Es como tener un control remoto para generar dígitos! \n",
    "\n",
    "🕹️ **¡Cambia el contenido de ese vector y verás qué sucede!** \n",
    "\n",
    "💫 **Mi experimento sugerido para ti**: Prueba con `[-56,5]`, ¿qué crees que va a pasar? ¡Spoiler alert: va a ser interesante! 😄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z = [-1, -1]  # 2D latent vector\n",
    "\n",
    "z_torch = torch.tensor(z, dtype=torch.float).cuda()  # convert Z into a PyTorch tensor\n",
    "\n",
    "sample = vae_decoder(z_torch).reshape(data_shape)  # decode the latent vector with the VAE decoder\n",
    "\n",
    "plt.imshow(sample.detach().cpu().numpy())  # plot the resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
