{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Generando dÃ­gitos con PyTorch: Â¡Tu primera aventura en IA Generativa! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¥ Â¡Bienvenido al mundo de PyTorch! \n",
    "\n",
    "PyTorch es una de las bibliotecas de deep learning mÃ¡s utilizadas en el mundo. ğŸ’ª Aunque algunas partes de esta sesiÃ³n prÃ¡ctica pueden parecer un poco intimidantes si es tu primera vez con PyTorch, Â¡no te preocupes! Todos hemos estado ahÃ­. ğŸ˜Š\n",
    "\n",
    "Si eres principiante, te recomiendo encarecidamente que primero te familiarices con PyTorch a travÃ©s de estos tutoriales:\n",
    "\n",
    "* ğŸ“š [Deep Learning Con PyTorch: Un Tutorial de 60 Minutos](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* ğŸ–¼ï¸ [Entrenando un Clasificador en CIFAR10](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
    "\n",
    "Una vez que domines estos conceptos bÃ¡sicos, estarÃ¡s listo para crear tus propios autoencoders. \n",
    "\n",
    "ğŸ’¡ **Mi consejo para ti**: Si quieres profundizar en los aspectos tÃ©cnicos de PyTorch despuÃ©s de este ejercicio, navega por los tutoriales oficiales. Â¡DescubrirÃ¡s que PyTorch es una herramienta realmente poderosa! âš¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ” Â¡Empecemos explorando nuestros datos!\n",
    "\n",
    "Â¿Conoces el conjunto de datos MNIST? ğŸ“Š Es como el \"Hola Mundo\" del machine learning, Â¡y hoy serÃ¡ tu mejor amigo!\n",
    "\n",
    "**El conjunto de datos MNIST (Modified National Institute of Standards and Technology)** es una colecciÃ³n de dÃ­gitos escritos a mano que vas a usar para entrenar tu sistema de procesamiento de imÃ¡genes. \n",
    "\n",
    "ğŸ“‹ **Â¿QuÃ© contiene exactamente?**\n",
    "- âœ… **60,000 imÃ¡genes de entrenamiento** (para que tu modelo aprenda)\n",
    "- âœ… **10,000 imÃ¡genes de prueba** (para evaluar quÃ© tan bien aprendiÃ³)\n",
    "- âœ… **Cada imagen es de 28x28 pÃ­xeles** en escala de grises\n",
    "- âœ… **Los valores van de 0 (negro) a 1 (blanco)**\n",
    "- âœ… **Cada imagen estÃ¡ etiquetada** con el dÃ­gito que representa (0-9)\n",
    "\n",
    "ğŸ¯ **Â¿Por quÃ© es tan importante?** Es considerado el punto de partida perfecto para cualquiera que quiera adentrarse en el reconocimiento de patrones y las redes neuronales. Â¡Es tu puerta de entrada al mundo de la IA!\n",
    "\n",
    "ğŸ’« **Â¡Vamos a visualizarlos y ver quÃ© magia puedes crear!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from src_vae.visualization.utils import display_data_samples\n",
    "\n",
    "# MNIST consists of 28x28 images, so the size of the data is\n",
    "data_shape = 28, 28\n",
    "data_size = data_shape[0] * data_shape[1]\n",
    "\n",
    "# Download and prepare data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = MNIST(root=\"data\", download=True, train=True, transform=transform)\n",
    "mnist_test = MNIST(root=\"data\", download=True, train=False, transform=transform)\n",
    "\n",
    "# Check data by displaying random images\n",
    "samples_indices = np.random.randint(len(mnist_train), size=10)\n",
    "mnist_img_list = [mnist_train[sample_idx][0] for sample_idx in samples_indices]\n",
    "display_data_samples(data=mnist_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are `mnist_train` and `mnist_test`?  Let's look at it.\n",
    "print(mnist_train)\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“¥ Â¡Cargando nuestros datos como un pro!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the first training image and its class label\n",
    "sample_image = mnist_train[0][0]  # sample_image is a \"PyTorch tensor\"\n",
    "sample_label = mnist_train[0][1]\n",
    "\n",
    "# Convert the Tensor into a numpy array\n",
    "sample_image_np = sample_image.numpy()\n",
    "print(\"Image size = \", sample_image_np.shape)\n",
    "\n",
    "# Call \"squeeze\" to remove the first dimension\n",
    "sample_image_np = sample_image_np.squeeze(0)\n",
    "print(\"Image size = \", sample_image_np.shape)\n",
    "\n",
    "# Plot\n",
    "plt.imshow(sample_image_np)\n",
    "print(\"The image label is \", sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ—ï¸ Â¡Construyamos tu primer autoencoder profundo!\n",
    "\n",
    "Â¡Ahora viene la parte emocionante! ğŸ‰ Vamos a construir un autoencoder simple pero poderoso usando solo:\n",
    "\n",
    "ğŸ§  **Capas densas** (tambiÃ©n conocidas como completamente conectadas) - En PyTorch las llamamos **Linear**  \n",
    "âš¡ **Funciones de activaciÃ³n ReLU** - Para dar vida a nuestras neuronas\n",
    "\n",
    "ğŸ“ **Arquitectura que crearemos:**\n",
    "\n",
    "- ğŸ”— **Codificador y decodificador**: Ambos con **3 capas** cada uno\n",
    "- ğŸ¯ **Espacio latente**: **32 dimensiones** (Â¡aquÃ­ es donde ocurre la magia!)\n",
    "- ğŸŒŸ **FunciÃ³n de activaciÃ³n final**: **Sigmoid** (perfecta porque nuestros pÃ­xeles van de 0 a 1)\n",
    "\n",
    "Â¿EstÃ¡s listo para ver cÃ³mo tu autoencoder aprende a \"entender\" y recrear dÃ­gitos? Â¡Vamos allÃ¡! ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "# Let's define the encoder architecture we want,\n",
    "# with some options to configure the input and output size\n",
    "def make_encoder(data_size, latent_space_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(data_size, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, latent_space_size),\n",
    "    )\n",
    "\n",
    "\n",
    "# Same thing for the decoder\n",
    "def make_decoder(data_size, latent_space_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(latent_space_size, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, data_size),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "\n",
    "# Now let's build our networks, with an arbitrary dimensionality of the latent space\n",
    "# and an input and output size depending on the data.\n",
    "latent_space_size = 2\n",
    "encoder = make_encoder(data_size, latent_space_size)\n",
    "decoder = make_decoder(data_size, latent_space_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤” Â¡Momento de reflexiÃ³n!\n",
    "* ğŸ¨ **Â¿QuÃ© vamos a generar?**\n",
    "* ğŸ“ **Â¿CuÃ¡l es el tamaÃ±o del espacio latente del autoencoder?**\n",
    "\n",
    "ğŸ’­ *TÃ³mate un momento para pensar en estas preguntas antes de continuar...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def autoencoder_forward_pass(encoder, decoder, x):\n",
    "    \"\"\"AE forward pass.\n",
    "\n",
    "    Args:\n",
    "        encoder: neural net that predicts a latent vector\n",
    "        decoder: neural net that projects a point in the latent space back into the image space\n",
    "        x: batch of N MNIST images\n",
    "\n",
    "    Returns:\n",
    "        loss: crossentropy loss\n",
    "        x_hat: batch of N reconstructed images\n",
    "    \"\"\"\n",
    "    in_shape = x.shape  # Save the input shape\n",
    "    encoder_input = torch.flatten(x, start_dim=1)  # Flatten the 2D image to a 1D tensor (for the linear layer)\n",
    "    z = encoder(encoder_input)  # Forward pass on the encoder (to get the latent space vector)\n",
    "    x_hat = decoder(z)  # Forward pass on the decoder (to get the reconstructed input)\n",
    "    x_hat = x_hat.reshape(in_shape)  # Restore the output to the original shape\n",
    "    loss = F.binary_cross_entropy(x_hat, x)  # Compute the reconstruction loss\n",
    "    return loss, x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Â¡Entrenamiento del modelo en acciÃ³n!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Define some training hyperparameters\n",
    "epochs = 25\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "def train(forward_pass_fn, encoder, decoder, optimizer, train_data, val_data, device=\"cuda\"):\n",
    "    # Create dataloaders from the data\n",
    "    # Those are PyTorch's abstraction to help iterate over the data\n",
    "    data_loader_kwargs = {\"batch_size\": batch_size, \"num_workers\": os.cpu_count() - 1, \"pin_memory\": True}\n",
    "    train_dataloader = DataLoader(train_data, shuffle=True, **data_loader_kwargs)\n",
    "    val_dataloader = DataLoader(val_data, **data_loader_kwargs)\n",
    "\n",
    "    # Ensure that the networks are on the requested device (typically a GPU)\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    fit_pbar = tqdm(range(epochs), desc=\"Training\", unit=\"epoch\")\n",
    "    pbar_metrics = {\"train_loss\": None, \"val_loss\": None}\n",
    "    for epoch in fit_pbar:\n",
    "        # Train once over all the training data\n",
    "        for x, _ in train_dataloader:\n",
    "            x = x.to(device)  # Move the data tensor to the device\n",
    "            optimizer.zero_grad()  # Make sure gradients are reset\n",
    "            train_loss, _ = forward_pass_fn(encoder, decoder, x)  # Forward pass\n",
    "            train_loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update parameters w.r.t. optimizer and gradients\n",
    "            pbar_metrics[\"train_loss\"] = train_loss.item()\n",
    "            fit_pbar.set_postfix(pbar_metrics)\n",
    "\n",
    "        # At the end of the epoch, check performance against the validation data\n",
    "        for x, _ in val_dataloader:\n",
    "            x = x.to(device)  # Move the data tensor to the device\n",
    "            val_loss, _ = forward_pass_fn(encoder, decoder, x)\n",
    "            pbar_metrics[\"val_loss\"] = val_loss.item()\n",
    "            fit_pbar.set_postfix(pbar_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*encoder.parameters(), *decoder.parameters()])\n",
    "train(autoencoder_forward_pass, encoder, decoder, optimizer, mnist_train, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‰ **Â¡Momento de la verdad!** Vamos a visualizar los resultados para el conjunto de test y ver quÃ© tan bien tu modelo aprendiÃ³ a reconstruir los dÃ­gitos ğŸ”âœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from src_vae.visualization.utils import display_autoencoder_results\n",
    "\n",
    "display_autoencoder_results(mnist_test, lambda x: autoencoder_forward_pass(encoder, decoder, x.cuda())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ—ºï¸ Explorando el espacio latente\n",
    "\n",
    "ğŸ¯ **Â¡Hora de un experimento sÃºper interesante!** \n",
    "\n",
    "Antes de pasar al autoencoder variacional, voy a hacer algo genial contigo. Regresa al inicio de este notebook y cambia el tamaÃ±o del espacio latente de **32 a 2 dimensiones** y vuelve a entrenar tu autoencoder.\n",
    "\n",
    "ğŸ”„ **Â¿Por quÃ© 2 dimensiones?** Â¡Porque podrÃ¡s visualizar el espacio latente en un grÃ¡fico 2D y ver exactamente cÃ³mo tu modelo \"entiende\" los dÃ­gitos!\n",
    "\n",
    "âœ¨ **Una vez que hayas hecho el cambio y reentrenado**, ejecuta la siguiente celda para explorar visualmente tu espacio latente. Â¡PrepÃ¡rate para sorprenderte! ğŸ¤©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell only if the autoencoder has a latent space size of 2.\n",
    "\n",
    "from src_vae.visualization.latent_space import explore_latent_space\n",
    "\n",
    "latent_space_size = 2\n",
    "\n",
    "explore_latent_space(\n",
    "    mnist_test,\n",
    "    lambda x: encoder(torch.flatten(x, start_dim=1)),\n",
    "    lambda z: decoder(z).reshape(data_shape),\n",
    "    encodings_label=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤” Â¡Pregunta para reflexionar!\n",
    "\n",
    "ğŸ’­ **Â¿Por quÃ© crees que con un espacio latente de 2 dimensiones obtienes imÃ¡genes reconstruidas menos precisas (mÃ¡s borrosas)?**\n",
    "\n",
    "*Piensa en tÃ©rminos de la cantidad de informaciÃ³n que puede almacenar un espacio de 2 dimensiones vs uno de 32 dimensiones...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒŸ Â¡Convirtamos tu autoencoder en VARIACIONAL!\n",
    "\n",
    "ğŸ‰ **Â¡LlegÃ³ el momento estelar!** Los autoencoders variacionales (VAE) son la evoluciÃ³n natural de lo que acabas de crear. Son muy similares, pero con superpoderes adicionales. ğŸ’«\n",
    "\n",
    "ğŸ” **Â¿CuÃ¡les son las 3 diferencias clave que te enseÃ±arÃ©?**\n",
    "\n",
    "1. ğŸ“Š **El codificador del VAE genera vectores de media y varianza** (en lugar de un solo vector)\n",
    "2. ğŸ² **La entrada del decodificador es un vector muestreado aleatoriamente** de una distribuciÃ³n Normal determinada por esos vectores de media y varianza\n",
    "3. ğŸ“ˆ **La funciÃ³n de pÃ©rdida tiene 2 tÃ©rminos**: \n",
    "   - âœ… La pÃ©rdida de reconstrucciÃ³n (como en tu AE normal) \n",
    "   - âœ… **+ la divergencia KL** (para la salida del codificador)\n",
    "\n",
    "ğŸ§  **El truco de reparametrizaciÃ³n**: Como el gradiente no puede retropropagarse a travÃ©s de un mÃ©todo de muestreo aleatorio, los VAE siempre vienen con este elegante truco matemÃ¡tico. Â¡Es lo que hace posible que todo funcione! âš¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "# Esta vez, empezamos directamente con un espacio latente de 2 dimensiones para visualizarlo fÃ¡cilmente despuÃ©s\n",
    "latent_space_size = 2\n",
    "\n",
    "# En la prÃ¡ctica, un pequeÃ±o truco para implementar fÃ¡cilmente las dos salidas del \n",
    "# codificador es simplemente duplicar el tamaÃ±o de su salida. Luego, podemos dividir \n",
    "# la salida por la mitad durante el paso hacia adelante!\n",
    "vae_encoder = make_encoder(data_size, latent_space_size * 2)\n",
    "vae_decoder = make_decoder(data_size, latent_space_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Â¡Preguntas para que reflexiones!\n",
    "\n",
    "ğŸ¤” **En la celda anterior**, usamos la misma funciÃ³n para construir las redes del codificador y decodificador del VAE que para el AE. La Ãºnica diferencia es que el tamaÃ±o de salida del codificador estÃ¡ multiplicado por 2. **Â¿Por quÃ© crees que es asÃ­?**\n",
    "\n",
    "ğŸ”§ **En la siguiente celda**, incluyo el **truco de reparametrizaciÃ³n** en el **paso hacia adelante**. **Â¿Recuerdas por quÃ© esto tiene que hacerse?**\n",
    "\n",
    "ğŸ“ **Â¿CuÃ¡l es el tamaÃ±o del espacio latente del VAE?**\n",
    "\n",
    "ğŸ’¡ *TÃ³mate un momento para pensar en estas preguntas. Â¡Te ayudarÃ¡n a entender mejor la magia detrÃ¡s de los VAE!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš™ï¸ Â¡Implementando el famoso \"truco de reparametrizaciÃ³n\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "def kl_div(mu, logvar):\n",
    "    kl_div_by_samples = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "    return torch.mean(kl_div_by_samples)\n",
    "\n",
    "\n",
    "def vae_forward_pass(encoder, decoder, x):\n",
    "    \"\"\"VAE forward pass.\n",
    "\n",
    "    Args:\n",
    "        encoder: neural net that predicts a mean and a logvar vector\n",
    "        decoder: neural net that projects a point in the latent space back into the image space\n",
    "        x: batch of N MNIST images\n",
    "\n",
    "    Returns:\n",
    "        loss: crossentropy + kl_divergence loss\n",
    "        x_hat: batch of N reconstructed images\n",
    "    \"\"\"\n",
    "    in_shape = x.shape  # Save the input shape\n",
    "    encoder_input = torch.flatten(x, start_dim=1)  # Flatten the 2D image to a 1D tensor (for the linear layer)\n",
    "    encoding_distr = encoder(encoder_input)  # Forward pass on the encoder (to get the latent space posterior)\n",
    "    # Nothing changed so far!\n",
    "\n",
    "    # Second part of our trick!\n",
    "    # We separate the (unique) latent space posterior into its two halves: mean and logvar\n",
    "    mu, logvar = encoding_distr[:, :latent_space_size], encoding_distr[:, latent_space_size:]\n",
    "\n",
    "    # Reparametrization trick\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    z = mu + eps * std\n",
    "\n",
    "    # Decoding mostly stays the same. The only difference is the added 4th line below\n",
    "    x_hat = decoder(z)  # Forward pass on the decoder (to get the reconstructed input)\n",
    "    x_hat = x_hat.reshape(in_shape)  # Restore the output to the original shape\n",
    "    loss = F.binary_cross_entropy(x_hat, x)  # Compute the reconstruction loss\n",
    "    loss += 5e-3 * kl_div(mu, logvar)  # Loss now also includes the KL divergence term\n",
    "    return loss, x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš€ **Â¡Vamos a entrenar tu VAE y ver la magia en acciÃ³n!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*vae_encoder.parameters(), *vae_decoder.parameters()])\n",
    "train(vae_forward_pass, vae_encoder, vae_decoder, optimizer, mnist_train, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸŠ **Â¡Echemos un vistazo a los resultados de tu VAE entrenado!** \n",
    "\n",
    "ğŸ’¡ Recuerda que tu VAE tiene un espacio latente de 2 dimensiones, Â¡asÃ­ que podremos visualizarlo en un grÃ¡fico de dispersiÃ³n! âœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "display_autoencoder_results(mnist_test, lambda x: vae_forward_pass(vae_encoder, vae_decoder, x.cuda())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Â¡MÃ¡s visualizaciones espectaculares!\n",
    "\n",
    "ğŸŒŸ **Â¡Ahora que tienes un espacio latente en dos dimensiones**, puedes visualizarlo fÃ¡cilmente y observar cÃ³mo se distribuyen los datos de una manera sÃºper cool!\n",
    "\n",
    "### ğŸ‘€ Â¿Ves la diferencia entre este espacio latente y el del autoencoder anterior?\n",
    "\n",
    "ğŸ’­ *Â¡Presta especial atenciÃ³n a cÃ³mo se organizan los diferentes dÃ­gitos en el espacio 2D!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from src_vae.visualization.latent_space import explore_latent_space\n",
    "\n",
    "explore_latent_space(\n",
    "    mnist_test,\n",
    "    lambda x: vae_encoder(torch.flatten(x, start_dim=1))[:, :latent_space_size],\n",
    "    lambda z: vae_decoder(z).reshape(data_shape),\n",
    "    encodings_label=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ® Â¡Hora de jugar con tu generador de dÃ­gitos!\n",
    "\n",
    "ğŸ¯ **En la siguiente celda**, te doy el poder de decodificar cualquier vector `z` que selecciones del espacio latente. Â¡Es como tener un control remoto para generar dÃ­gitos! \n",
    "\n",
    "ğŸ•¹ï¸ **Â¡Cambia el contenido de ese vector y verÃ¡s quÃ© sucede!** \n",
    "\n",
    "ğŸ’« **Mi experimento sugerido para ti**: Prueba con `[-56,5]`, Â¿quÃ© crees que va a pasar? Â¡Spoiler alert: va a ser interesante! ğŸ˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z = [-1, -1]  # 2D latent vector\n",
    "\n",
    "z_torch = torch.tensor(z, dtype=torch.float).cuda()  # convert Z into a PyTorch tensor\n",
    "\n",
    "sample = vae_decoder(z_torch).reshape(data_shape)  # decode the latent vector with the VAE decoder\n",
    "\n",
    "plt.imshow(sample.detach().cpu().numpy())  # plot the resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
