{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducción a las GANs\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Redes Generativas Adversarias\n",
    "============================\n",
    "\n",
    "¿Qué es una GAN?\n",
    "---------------\n",
    "\n",
    "Las GANs son un marco para enseñar a un modelo de aprendizaje profundo a capturar \n",
    "la distribución de los datos de entrenamiento para poder generar nuevos datos de esa \n",
    "misma distribución. Las GANs fueron inventadas por Ian Goodfellow en 2014 y descritas \n",
    "por primera vez en el artículo [Generative Adversarial Nets](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf). \n",
    "Están formadas por dos modelos distintos, un *generador* y un *discriminador*. El \n",
    "trabajo del generador es crear imágenes 'falsas' que parezcan imágenes de entrenamiento. \n",
    "El trabajo del discriminador es mirar una imagen y determinar si es una imagen real \n",
    "de entrenamiento o una imagen falsa del generador. Durante el entrenamiento, el \n",
    "generador está constantemente tratando de engañar al discriminador generando mejores \n",
    "falsificaciones, mientras que el discriminador está trabajando para convertirse en \n",
    "un mejor detective y clasificar correctamente las imágenes reales y falsas. El \n",
    "equilibrio de este juego se alcanza cuando el generador está generando falsificaciones \n",
    "perfectas que parecen provenir directamente de los datos de entrenamiento, y el \n",
    "discriminador se queda con una confianza del 50% al adivinar si la salida del \n",
    "generador es real o falsa.\n",
    "\n",
    "Ahora, definamos algunas notaciones que se utilizarán a lo largo del tutorial, \n",
    "comenzando con el discriminador. Sea $x$ los datos que representan una imagen. \n",
    "$D(x)$ es la red discriminadora que produce la probabilidad (escalar) de que $x$ \n",
    "provenga de los datos de entrenamiento en lugar del generador. Aquí, como estamos \n",
    "tratando con imágenes, la entrada a $D(x)$ es una imagen de tamaño CHW 3x64x64. \n",
    "Intuitivamente, $D(x)$ debería ser ALTO cuando $x$ proviene de los datos de \n",
    "entrenamiento y BAJO cuando $x$ proviene del generador. $D(x)$ también puede \n",
    "considerarse como un clasificador binario tradicional.\n",
    "\n",
    "Para la notación del generador, sea $z$ un vector de espacio latente muestreado \n",
    "de una distribución normal estándar. $G(z)$ representa la función generadora que \n",
    "mapea el vector latente $z$ al espacio de datos. El objetivo de $G$ es estimar \n",
    "la distribución de la que provienen los datos de entrenamiento ($p_{data}$) para \n",
    "poder generar muestras falsas de esa distribución estimada ($p_g$).\n",
    "\n",
    "Así, $D(G(z))$ es la probabilidad (escalar) de que la salida del generador $G$ \n",
    "sea una imagen real. Como se describe en el [artículo de Goodfellow](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), \n",
    "$D$ y $G$ juegan un juego minimax en el que $D$ intenta maximizar la probabilidad \n",
    "de clasificar correctamente reales y falsos ($logD(x)$), y $G$ intenta minimizar \n",
    "la probabilidad de que $D$ prediga que sus salidas son falsas ($log(1-D(G(z)))$). \n",
    "Del artículo, la función de pérdida GAN es\n",
    "\n",
    "$$\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}_{z\\sim p_{z}(z)}\\big[log(1-D(G(z)))\\big]$$\n",
    "\n",
    "En teoría, la solución a este juego minimax es donde $p_g = p_{data}$, y el \n",
    "discriminador adivina aleatoriamente si las entradas son reales o falsas. Sin \n",
    "embargo, la teoría de convergencia de las GANs todavía está siendo investigada \n",
    "activamente y en realidad los modelos no siempre se entrenan hasta este punto.\n",
    "\n",
    "¿Qué es una DCGAN?\n",
    "-----------------\n",
    "\n",
    "Una DCGAN es una extensión directa de la GAN descrita anteriormente, excepto que \n",
    "utiliza explícitamente capas convolucionales y convolucionales-transpuestas en el \n",
    "discriminador y generador, respectivamente. Fue descrita por primera vez por \n",
    "Radford et. al. en el artículo [Unsupervised Representation Learning With Deep \n",
    "Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf). \n",
    "El discriminador está compuesto por capas de [convolución](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) \n",
    "con stride, capas de [batch norm](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm2d) \n",
    "y activaciones [LeakyReLU](https://pytorch.org/docs/stable/nn.html#torch.nn.LeakyReLU). \n",
    "La entrada es una imagen de 3x64x64 y la salida es una probabilidad escalar de que \n",
    "la entrada provenga de la distribución de datos reales. El generador está compuesto \n",
    "por capas [convolucionales-transpuestas](https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d), \n",
    "capas de batch norm y activaciones [ReLU](https://pytorch.org/docs/stable/nn.html#relu). \n",
    "La entrada es un vector latente, $z$, que se extrae de una distribución normal \n",
    "estándar y la salida es una imagen RGB de 3x64x64. Las capas conv-transpuestas \n",
    "con stride permiten que el vector latente se transforme en un volumen con la misma \n",
    "forma que una imagen. En el artículo, los autores también dan algunos consejos \n",
    "sobre cómo configurar los optimizadores, cómo calcular las funciones de pérdida \n",
    "y cómo inicializar los pesos del modelo, todo lo cual se explicará en las \n",
    "secciones siguientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entradas\n",
    "========\n",
    "\n",
    "Definamos algunos términos para la ejecución:\n",
    "\n",
    "- `dataroot` - la ruta al directorio raíz del conjunto de datos. Hablaremos más sobre el conjunto de datos en la siguiente sección.\n",
    "- `workers` - el número de hilos trabajadores para cargar los datos con el `DataLoader`.\n",
    "- `batch_size` - el tamaño del lote usado en el entrenamiento. Nuestra GAN usa un tamaño de lote de 128.\n",
    "- `image_size` - el tamaño espacial de las imágenes usadas para el entrenamiento. Esta implementación usa por defecto 64x64. Si se desea otro tamaño, las estructuras de D y G deben ser modificadas.\n",
    "- `nc` - número de canales de color en las imágenes de entrada. Para imágenes a color esto es 3.\n",
    "- `nz` - longitud del vector latente.\n",
    "- `ngf` - relacionado con la profundidad de los mapas de características propagados por el generador.\n",
    "- `ndf` - establece la profundidad de los mapas de características propagados por el discriminador.\n",
    "- `num_epochs` - número de épocas de entrenamiento a ejecutar. Entrenar por más tiempo probablemente lleve a mejores resultados pero también tomará mucho más tiempo.\n",
    "- `lr` - tasa de aprendizaje para el entrenamiento. Como se describe en el artículo DCGAN, este número debe ser 0.0002.\n",
    "- `beta1` - hiperparámetro beta1 para los optimizadores Adam. Como se describe en el artículo, este número debe ser 0.5.\n",
    "- `ngpu` - número de GPUs disponibles. Si es 0, el código se ejecutará en modo CPU. Si este número es mayor que 0 se ejecutará en esa cantidad de GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"data/celeba\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos\n",
    "=====\n",
    "\n",
    "En este tutorial usaremos el [conjunto de datos de rostros Celeb-A](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) que se puede descargar en el sitio enlazado o en [One Drive](). El conjunto de datos se descargará como un archivo llamado `img_align_celeba.zip`. Una vez descargado, cree un directorio llamado `celeba` y extraiga el archivo zip en ese directorio. Luego, establezca la entrada `dataroot` para este notebook en el directorio `celeba` que acaba de crear. La estructura de directorios resultante debería ser:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación\n",
    "==============\n",
    "\n",
    "Con nuestros parámetros de entrada configurados y el conjunto de datos preparado, \n",
    "ahora podemos profundizar en la implementación. Comenzaremos con la estrategia \n",
    "de inicialización de pesos, luego hablaremos en detalle sobre el generador, el \n",
    "discriminador, las funciones de pérdida y el bucle de entrenamiento.\n",
    "\n",
    "Inicialización de Pesos\n",
    "-----------------------\n",
    "\n",
    "Según el artículo DCGAN, los autores especifican que todos los pesos del modelo \n",
    "deben inicializarse aleatoriamente a partir de una distribución Normal con \n",
    "`media=0` y `desviación_estándar=0.02`. La función `weights_init` toma un modelo \n",
    "inicializado como entrada y reinicializa todas las capas convolucionales, \n",
    "convolucionales-transpuestas y de normalización por lotes para cumplir con estos \n",
    "criterios. Esta función se aplica a los modelos inmediatamente después de su \n",
    "inicialización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on ``netG`` and ``netD``\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generador\n",
    "=========\n",
    "\n",
    "El generador, $G$, está diseñado para mapear el vector del espacio latente ($z$) al espacio de datos. Como nuestros datos son imágenes, convertir $z$ al espacio de datos significa crear una imagen RGB del mismo tamaño que las imágenes de entrenamiento (es decir, 3x64x64). En la práctica, esto se logra a través de una serie de capas convolucionales transpuestas bidimensionales con stride, cada una emparejada con una capa de normalización por lotes 2d y una activación relu. La salida del generador pasa por una función tanh para devolverla al rango de datos de entrada de $[-1,1]$. Vale la pena notar la existencia de las funciones de normalización por lotes después de las capas conv-transpuestas, ya que esta es una contribución crítica del artículo DCGAN. Estas capas ayudan con el flujo de gradientes durante el entrenamiento. A continuación se muestra una imagen del generador del artículo DCGAN.\n",
    "\n",
    "![](https://pytorch.org/tutorials/_static/img/dcgan_generator.png)\n",
    "\n",
    "Observa cómo las entradas que establecimos en la sección de entrada (`nz`, `ngf` y `nc`) influyen en la arquitectura del generador en el código. `nz` es la longitud del vector de entrada z, `ngf` se relaciona con el tamaño de los mapas de características que se propagan a través del generador, y `nc` es el número de canales en la imagen de salida (establecido en 3 para imágenes RGB). A continuación está el código del generador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos crear una instancia del generador y aplicar la función `weights_init`. \n",
    "Observa el modelo impreso para ver cómo está estructurado el objeto generador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-GPU if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "#  to ``mean=0``, ``stdev=0.02``.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminador\n",
    "=============\n",
    "\n",
    "Como se mencionó, el discriminador, $D$, es una red de clasificación binaria que toma una imagen como entrada y produce una probabilidad escalar de que la imagen de entrada sea real (en contraposición a falsa). Aquí, $D$ toma una imagen de entrada de 3x64x64, la procesa a través de una serie de capas Conv2d, BatchNorm2d y LeakyReLU, y produce la probabilidad final a través de una función de activación Sigmoid. Esta arquitectura se puede extender con más capas si es necesario para el problema, pero hay aspectos significativos en el uso de la convolución con stride, BatchNorm y LeakyReLUs. El artículo DCGAN menciona que es una buena práctica usar convolución con stride en lugar de pooling para reducir el muestreo porque permite que la red aprenda su propia función de pooling. Además, las funciones de normalización por lotes y leaky relu promueven un flujo saludable del gradiente, lo cual es crítico para el proceso de aprendizaje tanto de $G$ como de $D$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código del discriminador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is ``(nc) x 64 x 64``\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf) x 32 x 32``\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*2) x 16 x 16``\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*4) x 8 x 8``\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*8) x 4 x 4``\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, al igual que con el generador, podemos crear el discriminador, aplicar la\n",
    "función `weights_init` e imprimir la estructura del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-GPU if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "    \n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "# like this: ``to mean=0, stdev=0.2``.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones de Pérdida y Optimizadores\n",
    "===================================\n",
    "\n",
    "Con $D$ y $G$ configurados, podemos especificar cómo aprenden a través de las funciones de pérdida y los optimizadores. Usaremos la función de pérdida de Entropía Cruzada Binaria ([BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)) que está definida en PyTorch como:\n",
    "\n",
    "$$\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right]$$\n",
    "\n",
    "Note cómo esta función proporciona el cálculo de ambos componentes logarítmicos en la función objetivo (es decir, $log(D(x))$ y $log(1-D(G(z)))$). Podemos especificar qué parte de la ecuación BCE usar con la entrada $y$. Esto se logra en el bucle de entrenamiento que viene pronto, pero es importante entender cómo podemos elegir qué componente deseamos calcular simplemente cambiando $y$ (es decir, las etiquetas GT).\n",
    "\n",
    "A continuación, definimos nuestra etiqueta real como 1 y la etiqueta falsa como 0. Estas etiquetas se usarán al calcular las pérdidas de $D$ y $G$, y esta es también la convención utilizada en el artículo GAN original. Finalmente, configuramos dos optimizadores separados, uno para $D$ y otro para $G$. Como se especifica en el artículo DCGAN, ambos son optimizadores Adam con tasa de aprendizaje 0.0002 y Beta1 = 0.5. Para hacer seguimiento del progreso de aprendizaje del generador, generaremos un lote fijo de vectores latentes extraídos de una distribución Gaussiana (es decir, fixed_noise). En el bucle de entrenamiento, periódicamente introduciremos este fixed_noise en $G$, y a lo largo de las iteraciones veremos cómo se forman imágenes a partir del ruido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the ``BCELoss`` function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento\n",
    "============\n",
    "\n",
    "Finalmente, ahora que tenemos definidas todas las partes del marco GAN, podemos \n",
    "entrenarla. Ten en cuenta que entrenar GANs es algo así como un arte, ya que una \n",
    "configuración incorrecta de hiperparámetros lleva al colapso del modo sin mucha \n",
    "explicación de lo que salió mal. Aquí, seguiremos de cerca el Algoritmo 1 del \n",
    "[artículo de Goodfellow](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), \n",
    "mientras seguimos algunas de las mejores prácticas mostradas en \n",
    "[ganhacks](https://github.com/soumith/ganhacks). Específicamente, \"construiremos \n",
    "diferentes mini-lotes para imágenes reales y falsas\", y también ajustaremos la \n",
    "función objetivo de G para maximizar $log(D(G(z)))$. El entrenamiento se divide \n",
    "en dos partes principales. La Parte 1 actualiza el Discriminador y la Parte 2 \n",
    "actualiza el Generador.\n",
    "\n",
    "**Parte 1 - Entrenar el Discriminador**\n",
    "\n",
    "Recuerda, el objetivo de entrenar el discriminador es maximizar la probabilidad \n",
    "de clasificar correctamente una entrada dada como real o falsa. En términos de \n",
    "Goodfellow, deseamos \"actualizar el discriminador ascendiendo su gradiente \n",
    "estocástico\". En la práctica, queremos maximizar $log(D(x)) + log(1-D(G(z)))$. \n",
    "Debido a la sugerencia de mini-lotes separados de [ganhacks](https://github.com/soumith/ganhacks), \n",
    "calcularemos esto en dos pasos. Primero, construiremos un lote de muestras reales \n",
    "del conjunto de entrenamiento, haremos un pase hacia adelante a través de $D$, \n",
    "calcularemos la pérdida ($log(D(x))$), y luego calcularemos los gradientes en un \n",
    "pase hacia atrás. En segundo lugar, construiremos un lote de muestras falsas con \n",
    "el generador actual, haremos un pase hacia adelante de este lote a través de $D$, \n",
    "calcularemos la pérdida ($log(1-D(G(z)))$), y *acumularemos* los gradientes con \n",
    "un pase hacia atrás. Ahora, con los gradientes acumulados tanto de los lotes \n",
    "completamente reales como completamente falsos, llamamos a un paso del optimizador \n",
    "del Discriminador.\n",
    "\n",
    "**Parte 2 - Entrenar el Generador**\n",
    "\n",
    "Como se indica en el artículo original, queremos entrenar el Generador minimizando \n",
    "$log(1-D(G(z)))$ en un esfuerzo por generar mejores falsificaciones. Como se \n",
    "mencionó, Goodfellow demostró que esto no proporciona gradientes suficientes, \n",
    "especialmente al principio del proceso de aprendizaje. Como solución, en su lugar \n",
    "deseamos maximizar $log(D(G(z)))$. En el código logramos esto: clasificando la \n",
    "salida del Generador de la Parte 1 con el Discriminador, calculando la pérdida de \n",
    "G *usando etiquetas reales como GT*, calculando los gradientes de G en un pase \n",
    "hacia atrás, y finalmente actualizando los parámetros de G con un paso del \n",
    "optimizador. Puede parecer contraintuitivo usar las etiquetas reales como etiquetas \n",
    "GT para la función de pérdida, pero esto nos permite usar la parte $log(x)$ de la \n",
    "`BCELoss` (en lugar de la parte $log(1-x)$) que es exactamente lo que queremos.\n",
    "\n",
    "Finalmente, haremos algunos informes estadísticos y al final de cada época \n",
    "pasaremos nuestro lote fixed_noise a través del generador para rastrear \n",
    "visualmente el progreso del entrenamiento de G. Las estadísticas de entrenamiento \n",
    "reportadas son:\n",
    "\n",
    "- **Loss_D** - pérdida del discriminador calculada como la suma de pérdidas para \n",
    "    los lotes completamente reales y completamente falsos ($log(D(x)) + log(1 - D(G(z)))$).\n",
    "- **Loss_G** - pérdida del generador calculada como $log(D(G(z)))$\n",
    "- **D(x)** - la salida promedio (a través del lote) del discriminador para el lote \n",
    "    completamente real. Esto debería comenzar cerca de 1 y luego teóricamente \n",
    "    converger a 0.5 cuando G mejore. Piensa por qué es esto.\n",
    "- **D(G(z))** - salidas promedio del discriminador para el lote completamente falso. \n",
    "    El primer número es antes de que D se actualice y el segundo número es después \n",
    "    de que D se actualice. Estos números deberían comenzar cerca de 0 y converger a \n",
    "    0.5 a medida que G mejore. Piensa por qué es esto.\n",
    "\n",
    "**Nota:** Este paso puede llevar un tiempo, dependiendo de cuántas épocas ejecutes \n",
    "y si eliminaste algunos datos del conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            \n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados\n",
    "==========\n",
    "\n",
    "Finalmente, veamos cómo nos fue. Aquí, examinaremos tres resultados diferentes. \n",
    "Primero, veremos cómo cambiaron las pérdidas de D y G durante el entrenamiento. \n",
    "Segundo, visualizaremos la salida de G en el lote fixed_noise para cada época. Y \n",
    "tercero, veremos un lote de datos reales junto a un lote de datos falsos de G.\n",
    "\n",
    "**Pérdida versus iteración de entrenamiento**\n",
    "\n",
    "A continuación se muestra una gráfica de las pérdidas de D y G versus las \n",
    "iteraciones de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualización del progreso del Generador**\n",
    "\n",
    "Recuerda que guardamos la salida del generador en el lote fixed_noise después de cada época de entrenamiento. Ahora, podemos visualizar la progresión del entrenamiento de G con una animación. Presiona el botón de reproducción para iniciar la animación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imágenes Reales vs. Imágenes Falsas**\n",
    "\n",
    "Finalmente, veamos algunas imágenes reales y falsas lado a lado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
